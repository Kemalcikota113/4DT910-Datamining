{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffce46a4",
   "metadata": {},
   "source": [
    "# A1 - Data Mining - Local Outlier Detection (LOF)\n",
    "\n",
    "In this assignment i will be implementing the Local Outlier Detection algorithm in python and collect the Local Outlier Factor (LOF) for all points in the given dataset. For validation of the algorithm implementation i will use a built-in solution for the same problem via a python library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "38a0896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# read the data\n",
    "data = pd.read_csv('data/artificial_dataset.csv') # can be changed to: class_example_dataset.csv, custom_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e1493",
   "metadata": {},
   "source": [
    "For this assignment, i tried following the logic of the algorithm as shown in the slides as closely as possible with all of the different steps as an outline for my code.\n",
    "\n",
    "The first step is simple, we just want to calculate the euclidean distance between all of the data points. In the end i just print the dimensions of the matrix because since we have 19 samples in the dataset, i expect us to get a 19x19 matrix, which we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4b7db016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix shape: (19, 19)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: calculate pairwise distance matrix manually\n",
    "\n",
    "num_samples = data.shape[0]\n",
    "distance_matrix = np.zeros((num_samples, num_samples))\n",
    "for i in range(num_samples):\n",
    "    for j in range(num_samples):\n",
    "        distance_matrix[i, j] = np.linalg.norm(data.iloc[i] - data.iloc[j])\n",
    "\n",
    "# print(distance_matrix)\n",
    "# Print matrix dimensions\n",
    "print(\"Distance matrix shape:\", distance_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f4c5c0",
   "metadata": {},
   "source": [
    "Then, i will take each row of the matrix and sort the elements for each row. Then i will take the k-th value in each row and then exclude everything else. I do that by just putting it in a new list so i can use it further in the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "835a8190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.26400725 0.85339749 1.27157149 0.4776837  0.59034546 1.31952402\n",
      " 0.5327643  0.83583394 0.5327643  0.94839886 0.68782789 1.31542968\n",
      " 0.88983426 0.79641614 0.66023746 0.5551712  0.71139371 0.88983426\n",
      " 0.59935623]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Choose k and find k-distance\n",
    "\n",
    "k = 3 # Change k value here if needed\n",
    "\n",
    "k_distance = np.zeros(num_samples)\n",
    "for i in range(num_samples):\n",
    "    sorted_distances = np.sort(distance_matrix[i])\n",
    "    k_distance[i] = sorted_distances[k]  # k-th nearest neighbor distance\n",
    "\n",
    "print(k_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b2bd9",
   "metadata": {},
   "source": [
    "Now we calculate the ARD to see how \"reachable\" a given point is to its neighborhood. In dense areas neighbors have small k-distances so we will use that distance but in sparser areas the actual distances are larger so we use actual distance and we will then take the average of this mix of values to get an average of all distances to the k-nearest neighbors.\n",
    "\n",
    "So relatively, a lower ARD should mean that a point is in a dense neighborhood and on the other hand a higher ARD means its a sparse region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9f2db657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.20378106 0.84528395 1.04919658 0.58445216 0.55751358 1.0984628\n",
      " 0.60228805 0.77285651 0.53359782 0.85128635 0.57356093 1.30711545\n",
      " 0.98543368 0.64744812 0.60492163 0.64914053 0.81110303 0.81820849\n",
      " 0.60492163]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define the Average Reachability Distance (ARD) of each point\n",
    "\n",
    "def average_reachability_distance(point_index, neighbors):\n",
    "    reachability_distances = []\n",
    "    for neighbor in neighbors:\n",
    "        reachability_distance = max(k_distance[neighbor], distance_matrix[point_index, neighbor])\n",
    "        reachability_distances.append(reachability_distance)\n",
    "    return np.mean(reachability_distances)\n",
    "\n",
    "# Do it but not in a function\n",
    "average_reachability_distances = np.zeros(num_samples)\n",
    "for i in range(num_samples):\n",
    "    # Find k nearest neighbors\n",
    "    neighbors = np.argsort(distance_matrix[i])[:k+1]  # +1 to include the point itself\n",
    "    neighbors = neighbors[neighbors != i]  # Exclude the point itself\n",
    "    average_reachability_distances[i] = average_reachability_distance(i, neighbors)\n",
    "\n",
    "print(average_reachability_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ac024",
   "metadata": {},
   "source": [
    "Then we calculate the LARD which is similar to ARD but it checks the reachability within its own neighborhood instead of on a global scale for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "19fd2924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82486516 0.74474438 0.8170301  0.5698156  0.57344601 0.70034084\n",
      " 0.58849937 0.6489963  0.58141793 0.72096978 0.61283811 0.88297537\n",
      " 0.81728575 0.57344601 0.6187834  0.59446806 0.70822094 0.88060689\n",
      " 0.59588666]\n"
     ]
    }
   ],
   "source": [
    "# step 3 (cont): Define the Local Average Reachability Distance (LARD) of each point\n",
    "local_average_reachability_distances = np.zeros(num_samples)\n",
    "for i in range(num_samples):\n",
    "    # Find k nearest neighbors (excluding the point itself)\n",
    "    neighbors = np.argsort(distance_matrix[i])[:k+1]  # +1 to include the point itself\n",
    "    neighbors = neighbors[neighbors != i]  # Exclude the point itself\n",
    "    local_average_reachability_distances[i] = np.mean(average_reachability_distances[neighbors])\n",
    "\n",
    "print(local_average_reachability_distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3f59a",
   "metadata": {},
   "source": [
    "Finally, we can calculate the LOF which is a ratio between the ARD/LARD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a4325cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Outlier Factors:\n",
      "LOF[0] = 1.4593670820006248\n",
      "LOF[1] = 1.1349987558779633\n",
      "LOF[2] = 1.2841590393871694\n",
      "LOF[3] = 1.025686494771743\n",
      "LOF[4] = 0.9722163429044278\n",
      "LOF[5] = 1.5684688587217182\n",
      "LOF[6] = 1.0234302359082514\n",
      "LOF[7] = 1.190848863248375\n",
      "LOF[8] = 0.9177526042390783\n",
      "LOF[9] = 1.1807517823940012\n",
      "LOF[10] = 0.9359093742032981\n",
      "LOF[11] = 1.4803532324597777\n",
      "LOF[12] = 1.2057394640508463\n",
      "LOF[13] = 1.1290480835999477\n",
      "LOF[14] = 0.9775983458348672\n",
      "LOF[15] = 1.091968714310732\n",
      "LOF[16] = 1.1452683591858566\n",
      "LOF[17] = 0.9291415979636373\n",
      "LOF[18] = 1.0151622296770906\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define Local Outlier Factor (LOF) for each point\n",
    "local_outlier_factors = np.zeros(num_samples)\n",
    "for i in range(num_samples):\n",
    "    if local_average_reachability_distances[i] == 0:\n",
    "        local_outlier_factors[i] = 0  # Avoid division by zero\n",
    "    else:\n",
    "        local_outlier_factors[i] = average_reachability_distances[i] / local_average_reachability_distances[i]\n",
    "print(\"Local Outlier Factors:\")\n",
    "for i in range(num_samples):\n",
    "    print(f\"LOF[{i}] = {local_outlier_factors[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e20b8",
   "metadata": {},
   "source": [
    "In the end for validation i use scikit-learns implementation of the same algorithm and then take the difference between the two solutions. From eyeballing it, i see that i am usually 2-3 decimals off from the scikit solution which i am pretty happy with. I think this comes down to what happens under the hood in scikit learns implementation. They might have their own optimizations in one or more of the steps which gives different final results.\n",
    "\n",
    "For all of the datasets in this folder, the results are fairly consistents which further validates for me that the implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bb3d17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF scores from scikit-learn:\n",
      "LOF[0] = 1.4598276095131641\n",
      "LOF[1] = 1.1575256624653327\n",
      "LOF[2] = 1.322508555580498\n",
      "LOF[3] = 1.0282266304891439\n",
      "LOF[4] = 0.9747957310865116\n",
      "LOF[5] = 1.6035921174242127\n",
      "LOF[6] = 1.0298322428460047\n",
      "LOF[7] = 1.2281449186838025\n",
      "LOF[8] = 0.9186806784470107\n",
      "LOF[9] = 1.2284465013325174\n",
      "LOF[10] = 0.9376974041923649\n",
      "LOF[11] = 1.4901109244953854\n",
      "LOF[12] = 1.2765625255563475\n",
      "LOF[13] = 1.1320435622068186\n",
      "LOF[14] = 0.9787511613882703\n",
      "LOF[15] = 1.0926565591853266\n",
      "LOF[16] = 1.1869558094739008\n",
      "LOF[17] = 0.9356773297867095\n",
      "LOF[18] = 1.0218489030440994\n",
      "\n",
      "\n",
      "Difference between manual LOF and scikit-learn LOF:\n",
      "[-0.00046053 -0.02252691 -0.03834952 -0.00254014 -0.00257939 -0.03512326\n",
      " -0.00640201 -0.03729606 -0.00092807 -0.04769472 -0.00178803 -0.00975769\n",
      " -0.07082306 -0.00299548 -0.00115282 -0.00068784 -0.04168745 -0.00653573\n",
      " -0.00668667]\n"
     ]
    }
   ],
   "source": [
    "# Calculate LOF using scikit-learn for validation\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=k)\n",
    "y_pred = lof.fit_predict(data)\n",
    "lof_scores = -lof.negative_outlier_factor_\n",
    "print(\"LOF scores from scikit-learn:\")\n",
    "for i in range(num_samples):\n",
    "    print(f\"LOF[{i}] = {lof_scores[i]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Compare the two LOF scores\n",
    "print(\"Difference between manual LOF and scikit-learn LOF:\")\n",
    "print(local_outlier_factors - lof_scores)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
